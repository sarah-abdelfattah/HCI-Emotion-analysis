{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smoking-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "experimental-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "active-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the files\n",
    "infile = open('s01.dat', 'rb')\n",
    "new_dict = pickle.load(infile, encoding=\"latin1\")\n",
    "infile.close()\n",
    "labels=[]\n",
    "data=[]\n",
    "\n",
    "for keys in new_dict:\n",
    "    if(keys=='labels'):\n",
    "        labels=new_dict[keys]\n",
    "    else:\n",
    "        data=new_dict[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-blame",
   "metadata": {},
   "source": [
    "#  LABELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "engaging-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ labels ------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# The combinations of Valence and Arousal can be converted to emotional states:\n",
    "    # High Arousal & Positive Valence (Excited, Happy)\n",
    "    # Low Arousal & Positive Valence (Calm, Relaxed)\n",
    "    # High Arousal & Negative Valence (Angry, Nervous)\n",
    "    # Low Arousal & Negative Valence (Sad, Bored)\n",
    "    \n",
    "# Arousal can range from inactive (e.g. uninterested, bored) to active (e.g. alert, excited)\n",
    "# valence ranges from unpleasant (e.g. sad, stressed) to pleasant (e.g. happy, elated)\n",
    "# Dominance ranges from a helpless and weak feeling (without con- trol) to an empowered feeling (in control of everything).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# valence, arousal, dominance, liking\n",
    "labels = np.array(labels)\n",
    "\n",
    "# dealing with LABELS and creating a dataframe\n",
    "valence = labels[:,0]\n",
    "arousal = labels[:,1]\n",
    "dominance = labels[:,2]\n",
    "liking = labels[:,3]\n",
    "\n",
    "results = pd.DataFrame({'valence': valence, 'arousal': arousal, 'dominance': dominance, 'liking': liking })\n",
    "# results.describe()\n",
    "\n",
    "\n",
    "valenceMedian = 4.5\n",
    "arousalMedian = 4.5\n",
    "\n",
    "# Function to check if each trial has positive or negative valence\n",
    "def positive_valence(trial):\n",
    "    return \"positive\" if results.iloc[trial]['valence'] >= valenceMedian else \"negative\"\n",
    "\n",
    "# Function to check if each trial has high or low arousal\n",
    "def high_arousal(trial):\n",
    "    return \"high\" if results.iloc[trial]['arousal'] >= arousalMedian else \"low\"\n",
    "\n",
    "\n",
    "# Convert ratings to high/low or positive/negative values\n",
    "labels_encoded = []\n",
    "for i in range (len(results)):\n",
    "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
    "labels_encoded = np.reshape(labels_encoded, (40, 2))\n",
    "labelsCategorized = pd.DataFrame(data=labels_encoded, columns=[\"valence\", \"arousal\"])\n",
    "\n",
    "\n",
    "# Dataset with only Valence column\n",
    "df_valence = labelsCategorized['valence']\n",
    "\n",
    "# Dataset with only Arousal column\n",
    "df_arousal = labelsCategorized['arousal']\n",
    "\n",
    "\n",
    "# High Arousal Positive Valence\n",
    "highArousal_posValence = results[(results['valence'] >= results['valence'].median()) & (results['arousal'] >= results['arousal'].median())]\n",
    "\n",
    "# Low Arousal Positive Valence dataset\n",
    "lowArousal_posValence = results[(results['valence'] >= results['valence'].median()) & (results['arousal'] < results['arousal'].median())]\n",
    "\n",
    "# High Arousal Negative Valence dataset\n",
    "highArousal_negValence = results[(results['valence'] < results['valence'].median()) & (results['arousal'] >= results['arousal'].median())]\n",
    "\n",
    "# Low Arousal Negative Valence dataset\n",
    "lowArousal_negValence = results[(results['valence'] < results['valence'].median()) & (results['arousal'] < results['arousal'].median())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-adelaide",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "lined-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "6\n",
      "8064\n"
     ]
    }
   ],
   "source": [
    "#------------------------ data ------------------------#\n",
    "        \n",
    "\n",
    "all_channels = np.array(['b1','b2', 'b3', 'b4', 'b5', 'b6','b7', 'b8', 'b9', 'b10','b11','b12', 'b13', 'b14', 'b15', 'b16','b17', 'b18', 'b19', 'b20','b21','b22', 'b23', 'b24', 'b25', 'b26','b27', 'b28', 'b29', 'b30', 'b31', 'b32', 'hEOG', 'vEOG', 'zEMG', 'tEMG', 'GSR', 'Respiration belt', 'Plethysmograph', 'Temp'])\n",
    "peripheral_channels = np.array([\"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])\n",
    "\n",
    "# drop unneeded data \n",
    "data = data[:, 34:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-forth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "avgValence = 0;\n",
    "avgArousal = 0;\n",
    "\n",
    "for s in range(0, 100):\n",
    "    print(s)\n",
    "    # random videos will be taken out for testing (20%)\n",
    "    randomIndexes = []\n",
    "\n",
    "    count = 0;\n",
    "    testPercentage = len(data)*20/100\n",
    "    while( count < testPercentage ):\n",
    "        randomNumber = random.randint(0,39) \n",
    "        if(not randomNumber in randomIndexes):\n",
    "            randomIndexes.append(randomNumber)\n",
    "            count = count+1\n",
    "    \n",
    "    \n",
    "    #dividing train and test\n",
    "    df_valence_result_test_temp = []\n",
    "    df_valence_result_train_temp = []\n",
    "\n",
    "    df_arousal_result_test_temp = []\n",
    "    df_arousal_result_train_temp = []\n",
    "\n",
    "\n",
    "    for i in range(0, len(df_valence)):\n",
    "        if(i in randomIndexes):\n",
    "            df_valence_result_test_temp.append(df_valence[i])\n",
    "            df_arousal_result_test_temp.append(df_arousal[i])\n",
    "        else:\n",
    "            df_valence_result_train_temp.append(df_valence[i])\n",
    "            df_arousal_result_train_temp.append(df_arousal[i])\n",
    "            \n",
    "    \n",
    "    \n",
    "    #repeating it \n",
    "    df_valence_result_test = []\n",
    "    df_valence_result_train = []\n",
    "\n",
    "    df_arousal_result_test = []\n",
    "    df_arousal_result_train = []\n",
    "    \n",
    "    for i in range(0,len(df_valence_result_train_temp)):\n",
    "        for j in range(0,8064):\n",
    "            df_valence_result_train.append(df_valence_result_train_temp[i])\n",
    "            df_arousal_result_train.append(df_arousal_result_train_temp[i])\n",
    "\n",
    "\n",
    "    for i in range(0,len(df_valence_result_test_temp)):\n",
    "        for j in range(0,8064):\n",
    "            df_valence_result_test.append(df_valence_result_test_temp[i])\n",
    "            df_arousal_result_test.append(df_arousal_result_test_temp[i])\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    #DATA\n",
    "    #convert it to dataframe\n",
    "    df_data_train = pd.DataFrame(columns = peripheral_channels)\n",
    "    df_data_test = pd.DataFrame(columns = peripheral_channels)\n",
    "    df_dataPerVideo = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len(data)): #video 40\n",
    "        df_dataPerVideo = pd.DataFrame() \n",
    "\n",
    "        for j in range(0, len(data[i])): #channel 6\n",
    "            temp = []\n",
    "            for k in range(0, len(data[i][j])): #value 8064\n",
    "                temp.append(data[i][j][k])\n",
    "            df_dataPerVideo[peripheral_channels[j]] = temp    \n",
    "\n",
    "        if(i in randomIndexes):\n",
    "            df_data_test = df_data_test.append(df_dataPerVideo, ignore_index = True)\n",
    "        else:\n",
    "            df_data_train = df_data_train.append(df_dataPerVideo, ignore_index = True)\n",
    "\n",
    "            \n",
    "    \n",
    "    # TRY FIRST VALENCE\n",
    "    \n",
    "    # apply standardization on numerical features\n",
    "    sc = StandardScaler()\n",
    "    standX_train = sc.fit_transform(df_data_train)\n",
    "    standX_test = sc.transform(df_data_test)\n",
    "\n",
    "    #Training and Predictions\n",
    "#     classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "#     classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "#     classifier = LogisticRegression()\n",
    "    classifier = RandomForestClassifier(n_estimators=100)\n",
    "#     classifier = GaussianNB()\n",
    "#     classifier = SVC(kernel='linear')\n",
    "#     classifier = SVC(kernel='rbf')\n",
    "    classifier.fit(standX_train, df_valence_result_train)\n",
    "\n",
    "    #make predictions on our test data\n",
    "    y_pred = classifier.predict(standX_test)\n",
    "\n",
    "    #Evaluating the Algorithm\n",
    "    avgValence = avgValence + accuracy_score(df_valence_result_test,y_pred)\n",
    "\n",
    "\n",
    "    \n",
    "    # TRY THEN AROUSAL\n",
    "    \n",
    "    # apply standardization on numerical features\n",
    "    sc = StandardScaler()\n",
    "    standX_train = sc.fit_transform(df_data_train)\n",
    "    standX_test = sc.transform(df_data_test)\n",
    "\n",
    "    #Training and Predictions\n",
    "#     classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "#     classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "#     classifier = LogisticRegression()\n",
    "    classifier = RandomForestClassifier(n_estimators=100)\n",
    "#     classifier = GaussianNB()\n",
    "#     classifier = SVC(kernel='linear')\n",
    "#     classifier = SVC(kernel='rbf')\n",
    "    classifier.fit(standX_train, df_arousal_result_train)\n",
    "\n",
    "    #make predictions on our test data\n",
    "    y_pred = classifier.predict(standX_test)\n",
    "\n",
    "    #Evaluating the Algorithm\n",
    "    avgArousal = avgArousal + accuracy_score(df_arousal_result_test,y_pred)\n",
    "    \n",
    "    \n",
    "print(\"Valence accuracy for 100 times: \", avgValence)\n",
    "print(\"Arousal accuracy for 100 times: \", avgArousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-hybrid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
